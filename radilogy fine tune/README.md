ğŸ©º Fine-Tuning LLaMA-2 (7B) for Automated Chest X-Ray Impression Generation using LoRA (QLoRA)
ğŸŒ Overview

This project presents an advanced Large Language Model (LLM) fine-tuned on radiology report data to automatically generate â€œimpressionâ€ sections from â€œfindingsâ€ in chest X-ray reports.
The model is based on Metaâ€™s LLaMA-2 (7B) and optimized using QLoRA â€” enabling high-performance fine-tuning on limited GPU resources.

The deployed Streamlit app allows clinicians, researchers, and students to input radiology findings and receive coherent, clinically-consistent impressions generated by the model.

ğŸ§  Model Highlights

Base model: meta-llama/Llama-2-7b-chat-hf

Fine-tuning method: LoRA (QLoRA) using 4-bit quantization

Dataset: Custom curated radiology report dataset (train / validate / test JSONL files)

Objective: Convert structured findings into concise impressions

Frameworks: PyTorch, Hugging Face Transformers, PEFT, and Accelerate


| Component          | Library                         |
| ------------------ | ------------------------------- |
| Model Architecture | LLaMA-2-7B                      |
| Fine-Tuning        | PEFT (QLoRA)                    |
| Tokenization       | SentencePiece                   |
| Dataset Handling   | Datasets                     |
| Evaluation         | ROUGE, BERTScore, NLTK          |
| Deployment         | Streamlit + Hugging Face Spaces |


ğŸš€ Features

ğŸ” Input a radiology report finding

ğŸ§  Get a generated impression in seconds

âš™ï¸ Powered by LLaMA-2 + LoRA

ğŸ’¬ Completely browser-based, no installation needed

ğŸ”’ Keeps patient data local to your session

âš™ï¸ Model Training Workflow

Data loading: JSONL format with inputs and target keys

Prompt formatting:

[INST] <findings> [/INST] <impression>


Tokenization: AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-chat-hf")

Fine-Tuning: prepare_model_for_kbit_training() + LoraConfig()

Evaluation: rouge-score, bert-score, and nltk metrics

Merged Output: Stored as radiology_llama_merged for inference and deployment


ğŸ–¥ï¸ Streamlit App

The demo interface allows users to:

Type radiology findings

Generate an impression instantly

View the modelâ€™s reasoning and adjust generation parameters

ğŸ’» Access it live here:
â¡ï¸ Launch App


ğŸ“¦ Files
app.py                  â†’ Streamlit interface
requirements.txt        â†’ Dependencies
radiology_llama_merged/ â†’ Fine-tuned model weights
README.md               â†’ Project documentation

ğŸ¤ Acknowledgements

Meta AI â€” for the original LLaMA-2 model

Hugging Face â€” for open-source model hosting and transformers

Stanford / MIMIC-CXR â€” for publicly available chest X-ray datasets



ğŸ§¬ License

This project is licensed under the Apache 2.0 License.
Please ensure compliance with Metaâ€™s LLaMA-2 usage terms for any redistribution or commercial use.